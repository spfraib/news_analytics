{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from operator import itemgetter\n",
    "import more_itertools as mit\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/scratch/spf248/news/data/'\n",
    "input_file   = 'reuters-econ-fin-mkt-'+datetime.today().strftime('%Y-%m')+'.pkl.xz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_data+'tone2keywords.pkl','rb') as f:\n",
    "    tone2keywords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in tone2keywords:\n",
    "    tone2keywords[name] = tone2keywords[name].set_index('word')['IDF'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Lists: strong, positive, negative, uncertainty, weak\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Lists:\", ', '.join(list(tone2keywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import News...\n",
      "Done in 244 Sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Import News...\")\n",
    "start = timer()\n",
    "articles = pd.read_pickle(path_to_data+input_file,compression='xz')\n",
    "articles = articles[['date', 'regions', 'subjects', 'title', 'snippet', 'body']].copy()\n",
    "print(\"Done in\", round(timer() - start),\"Sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(idx):\n",
    "    \n",
    "    text = ' '.join(list(articles.loc[idx, ['title','snippet','body']].replace(np.nan,'')))\n",
    "    \n",
    "    # Split into words and remove non-letter characters\n",
    "    tokens = re.sub(\"[^a-zA-Z]\",\" \", text.lower()).split()\n",
    "    \n",
    "    # Return Words and Their Count\n",
    "    counter = collections.Counter(tokens)\n",
    "\n",
    "    # Word Count\n",
    "    T = sum(counter.values())\n",
    "\n",
    "    values = [T]\n",
    "    index  = ['# words']\n",
    "\n",
    "    for name in sorted(tone2keywords):\n",
    "\n",
    "        # Tonal Words In the Text\n",
    "        words  = list(set(counter.keys())&set(tone2keywords[name].keys()))\n",
    "\n",
    "        if words:\n",
    "\n",
    "            # Tonal Words Counts\n",
    "            counts = itemgetter(*words)(counter)\n",
    "\n",
    "            # Tonal Words IDFs\n",
    "            idfs = itemgetter(*words)(tone2keywords[name])\n",
    "\n",
    "            if len(words) > 1:\n",
    "                tf = sum(counts)/T\n",
    "            else:\n",
    "                tf = counts/T\n",
    "                \n",
    "            tfidf = np.dot(counts,idfs)/T\n",
    "\n",
    "        else:\n",
    "\n",
    "            tf = 0\n",
    "            tfidf  = 0\n",
    "\n",
    "        values.append(tf)\n",
    "        index.append('% '+name)\n",
    "\n",
    "        values.append(tfidf)\n",
    "        index.append('% '+name+' tfidf')\n",
    "        \n",
    "    return pd.Series(values,index=index, name=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compute Sentiment...\\n\")\n",
    "start = timer()\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    sentiments = pd.DataFrame(pool.map(get_counts, articles.index))\n",
    "    \n",
    "end = timer()\n",
    "print(\"Done In\", round(end - start),\"Sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Save...\\n\")\n",
    "start = timer()\n",
    "\n",
    "sentiments.to_pickle(path_to_data+'sentiment-'+input_file,compression='xz')\n",
    "\n",
    "end = timer()\n",
    "print(\"Done In\", round(end - start),\"Sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
